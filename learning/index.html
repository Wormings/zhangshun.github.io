---
layout: default
title: Learning | Shun Zhang
home: passive
publication: passive
learning: active
projects: passive
cv: passive
description: Learning
---

<div class="cv">
	<h3> Paper Notes </h3>
	<p>
		<strong> Learning by Playing â€“ Solving Sparse Reward Tasks from Scratch </strong> </br>
		<a href="https://arxiv.org/pdf/1802.10567.pdf"> [Original Paper] </a>
		<a href="http://note.youdao.com/noteshare?id=695ebba9e6f5dfff4f513373d7be0883"> [Notes in Chinese] </a>
	</p>
	<p>
		<strong> IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures </strong> </br>
		<a href="https://arxiv.org/pdf/1802.01561.pdf"> [Original Paper] </a>
		<a href="http://note.youdao.com/noteshare?id=d84f53d18fbbbd5f2d9ce84a892b2fe1"> [Notes in Chinese] </a> </br>
		<a href="https://www.youtube.com/watch?v=TfhV51cndPY"> [Speech of Vlad Mnih] </a>
		<a href="http://note.youdao.com/noteshare?id=7c4854b5d5b443421a33e2624b818ae1"> [Notes in Chinese] </a>
	</p>
	<p>
		<strong> Kickstarting Deep Reinforcement Learning </strong> </br>
		<a href="https://arxiv.org/pdf/1803.03835.pdf"> [Original Paper] </a>
		<a href="http://note.youdao.com/noteshare?id=94c9b6341a8575d5bd0fdc7e1c73dc28"> [Notes in Chinese] </a>
	</p>
	<p>
		<strong> DARLA: Improving Zero-Shot Transfer in Reinforcement Learning </strong> </br>
		<a href="https://arxiv.org/pdf/1707.08475.pdf"> [Original Paper] </a>
		<a href="http://note.youdao.com/noteshare?id=e97d8f59f28a918d88f8606fcdf9cb93"> [Notes in Chinese] </a>
	</p>
	<p>
		<strong> Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks </strong> </br>
		<a href="https://arxiv.org/pdf/1511.06434.pdf"> [Original Paper] </a>
		<a href="http://note.youdao.com/noteshare?id=58bab11e1e3846c504c18750065efd2c"> [Notes in Chinese] </a>
	</p>
	<p>
		<strong> UBeyond Sparsity: Tree Regularization of Deep Models for Interpretability </strong> </br>
		<a href="https://arxiv.org/pdf/1711.06178.pdf"> [Original Paper] </a>
		<a href="http://note.youdao.com/noteshare?id=73ccc92d07bd4c73465a04514fd7a049"> [Notes in Chinese] </a>
	</p>
	<p>
		<strong> Practical Variational Inference for Neural Networks </strong> </br>
		<a href="http://papers.nips.cc/paper/4329-practical-variational-inference-for-neural-networks.pdf"> [Original Paper] </a>
		<a href="http://note.youdao.com/noteshare?id=5cd8cedc2a3e63d381d7238a1eb18393"> [Notes in Chinese] </a>
	</p>
	<p>
		<strong> Structured Control Nets for Deep Reinforcement Learning </strong> </br>
		<a href="https://arxiv.org/pdf/1802.08311.pdf"> [Original Paper] </a>
		<a href="http://note.youdao.com/noteshare?id=f54f04f5d2cf8fe7bf6e6e20e530635a"> [Notes in Chinese] </a>
	</p>
	<p>
		<strong> Continuous Adaption via Meta-Learning in Nonstationary and Competitive Environments </strong> </br>
		<a href="https://arxiv.org/pdf/1710.03641.pdf"> [Original Paper] </a>
		<a href="http://note.youdao.com/noteshare?id=30ffa59becff55fc02f47370d037ed44"> [Notes in Chinese] </a>
	</p>
	<p>
		<strong> The Mathematics of 2048: Optimal Play with Markov Decision Processes </strong> </br>
		<a href="http://jdlm.info/articles/2018/03/18/markov-decision-process-2048.html"> [Original Post] </a>
		<a href="http://note.youdao.com/noteshare?id=48bd6a06f064fdbb2503626b145f0244"> [Notes in Chinese] </a>
		<a href="https://github.com/jdleesmiller/twenty48"> [Codes] </a>
	</p>
	<strong> World models: can agents learn inside their own dreams? </strong> </br>
		<a href="https://arxiv.org/pdf/1803.10122.pdf"> [Original Paper] </a>
		<a href="http://note.youdao.com/noteshare?id=adb396a279bb3468ab8b0ad5c98817b0"> [Notes in Chinese] </a>
		<a href="https://worldmodels.github.io/"> [Demo Website] </a>
	</p>
</div>
